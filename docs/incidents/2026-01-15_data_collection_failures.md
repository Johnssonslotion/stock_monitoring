# Incident Report: 2026-01-15 Data Collection Failures

**Date**: 2026-01-15  
**Reporter**: Antigravity Dev Team  
**Severity**: CRITICAL  
**Status**: RESOLVED (with ongoing monitoring)

---

## Executive Summary

Multiple data collection failures occurred over 2 days (Jan 14-15), resulting in cumulative data loss of ~16,000 ticks (~20% of market hours). Root cause identified as systemic deployment process failure - no verification, no documentation, no automated checks. Emergency fixes applied but recurring pattern indicates need for comprehensive process improvements.

---

## Timeline

### Day 1: 2026-01-14

**09:00 KST** - Korean market opens  
**09:14 KST** - `real-collector` crashes (last network log entry)  
**Cause**: ALREADY_IN_SUBSCRIBE errors from KIS API  
**Mechanism**: WebSocket reconnection without explicit unsubscribe, causing duplicate subscription attempts  

**09:14-13:50 KST** - Data collection completely stopped  
**Impact**: **~4.8 hours of data loss** (~14,400 potential ticks)  

**13:50 KST** (estimated) - Manual intervention (details unclear - not documented)  
**Status**: Collector restarted but issue not resolved

---

### Day 2 Morning: 2026-01-15

**09:00 KST** - Market opens  
**Status**: `real-collector` still not auto-restarting (no `restart` policy in docker-compose.yml)  
**Impact**: Opening bell data lost (most valuable volatility data)  

**13:50-14:08 KST** - Emergency Fix #1 deployed  
**Action**: Added `cleanup_subscriptions()` method to websocket_base.py  
**Commit**: 8781ff5  
**Test Coverage**: NONE (deployed untested)  

---

### Day 2 Afternoon: 2026-01-15

**14:08 KST** - Emergency fix deployed, `real-collector` started  
**14:08-14:18 KST** - Collector publishing to Redis successfully  
**14:18 KST** - Post-deployment monitoring started (5-min intervals)  

**14:18 KST** - **CRITICAL DISCOVERY**: No ticks in database!  
**Investigation**:
```bash
# DB check
SELECT MAX(time) FROM market_ticks;
‚Üí 2026-01-15 05:08:28 (14:08 KST) - 10 minutes old!

# Collector logs
docker logs real-collector
‚Üí ‚úÖ Publishing ticker.kr @ 142,900Ïõê (real-time)

# Missing link?
docker ps | grep archiver
‚Üí ‚ùå timescale-archiver NOT RUNNING!
```

**Root Cause**: `timescale-archiver` had no `restart: unless-stopped` policy  
**Impact**: 12 minutes of data loss (14:08-14:20) = **~1,500 ticks**

**14:20 KST** - Emergency Fix #2  
**Action**: 
1. Manual start: `docker compose up -d timescale-archiver`  
2. Added `restart: unless-stopped` to docker-compose.yml  
**Commit**: 4fe80ca  

**14:21 KST** - Data collection resumed  
**Verification**:
```
docker logs timescale-archiver
‚Üí "Flushed 100 ticks to TimescaleDB" ‚úÖ

SELECT COUNT(*) FROM market_ticks WHERE time > NOW() - INTERVAL '1 minute';
‚Üí 1,510 ticks ‚úÖ
```

**14:24 KST** - User report: "Î©∞Ïπ†Ïß∏ ÎπÑÏä∑Ìïú ÏÉÅÌô©Ïù∏Îç∞ Ïû¨ÌòÑÎêòÎäîÍ±∞Í∞ôÏïÑ"  
**Council of Six**: Emergency re-convened  
**Decision**: Deployment freeze until documentation complete

---

## Root Cause Analysis

### Immediate Causes

1. **ALREADY_IN_SUBSCRIBE Errors**  
   - WebSocket `run()` method did not explicitly unsubscribe before reconnecting  
   - KIS API server retained subscription state  
   - Retry logic (3 attempts) all failed ‚Üí 0 ticks  

2. **Missing Restart Policies**  
   - `real-collector`: No restart policy ‚Üí manual intervention required  
   - `timescale-archiver`: No restart policy ‚Üí silent failure, undetected  

### Intermediate Causes

3. **No Post-Deployment Verification**  
   - Services deployed without checking runtime status  
   - Assumed "git pull + docker up" = success  
   - No data flow verification (collector ‚Üí redis ‚Üí archiver ‚Üí DB)  

4. **Silent Failures**  
   - Collector can publish to Redis forever, but if archiver dead ‚Üí NO DATA  
   - No alerts, no metrics, no monitoring  
   - Discovered only by manual SQL queries  

### Deep Causes (Systemic)

5. **No Deployment Process**  
   - No checklist  
   - No smoke tests  
   - No verification protocol  
   - "Hope and pray" deployment methodology  

6. **No Documentation Culture**  
   - Previous incidents not documented  
   - Learning lost daily (organizational amnesia)  
   - Each failure treated as "one-off" instead of pattern  

7. **No Monitoring Infrastructure**  
   - No Prometheus/Grafana  
   - No automated alerts  
   - Every diagnosis requires SSH + manual commands  

---

## Impact Assessment

### Data Loss

**Jan 14 (Day 1)**:  
- **Duration**: ~4.8 hours (09:00-13:50)  
- **Estimated Loss**: ~14,400 ticks  
- **Critical Loss**: Opening 30min (09:00-09:30) - highest volatility  

**Jan 15 (Day 2)**:  
- **Morning**: Unknown duration (likely hours)  
- **Afternoon**: 12 minutes (14:08-14:20)  
- **Estimated Loss**: ~1,500 ticks  

**Total 2-Day Impact**:  
- **~16,000 ticks lost**  
- **~20% of market hours** affected  
- **Opening bell data**: COMPLETELY MISSING (both days)  

### Business Impact

1. **Strategy Backtesting**: UNUSABLE  
   - Data has availability bias  
   - Missing critical volatility periods  
   - Results cannot be trusted  

2. **User Confidence**: DAMAGED  
   - Recurring failures  
   - No proactive communication  
   - "Î©∞Ïπ†Ïß∏ Í∞ôÏùÄ ÏÉÅÌô©" - user quote  

3. **Technical Debt**: ACCUMULATING  
   - Emergency fixes without tests  
   - Documentation debt increasing  
   - Each "fix" creates uncertainty  

---

## Resolution

### Emergency Fixes Applied

**Fix #1: WebSocket Cleanup (Commit 8781ff5)**
```python
async def cleanup_subscriptions(self):
    \"\"\"üßπ EMERGENCY FIX: Explicit cleanup before reconnect\"\"\"
    for market in self.active_markets:
        await self.unsubscribe_market(market)
    await asyncio.sleep(3)  # Grace period
```

**Fix #2: Archiver Restart Policy (Commit 4fe80ca)**
```yaml
timescale-archiver:
  # ... existing config ...
  restart: unless-stopped  # ‚Üê ADDED
```

### Verification

**14:21-14:30 KST**: Monitoring confirmed:
- ‚úÖ `real-collector`: Up, publishing
- ‚úÖ `timescale-archiver`: Up, flushing batches
- ‚úÖ DB: Receiving 1,500+ ticks/minute
- ‚ö†Ô∏è Still seeing occasional ALREADY_IN_SUBSCRIBE (non-critical)

---

## Prevention Measures

### Immediate (Deadline: 17:00 KST Today)

Per Council of Six decision, **deployment freeze** until:

1. **‚úÖ Incident Report** (this document)
2. **‚è≥ Runbook**: `docs/runbooks/data_collection_recovery.md`
3. **‚è≥ Deployment Checklist**: `docs/deployment/CHECKLIST.md`
4. **‚è≥ Monitoring Requirements**: `docs/infrastructure/monitoring_requirements.md`
5. **‚è≥ Update KNOWN_ISSUES.md**

### Short-Term (This Week)

1. **Automated Smoke Tests** (`tests/smoke/test_deployment.py`)
   - Verify all services running
   - Check data flow (collector ‚Üí redis ‚Üí archiver ‚Üí DB)
   - API health check
   - Run after EVERY deployment

2. **Health Check Endpoints**
   - GET /health/collector
   - GET /health/archiver  
   - Return service status, last activity, error count

3. **Service Restart Policies**
   - Audit ALL services in docker-compose.yml
   - Ensure `restart: unless-stopped` on critical services
   - Document which services should NOT auto-restart (one-offs)

### Medium-Term (Next Week)

4. **Prometheus + Grafana**
   - Metrics: collector_status, ticks_published, ticks_flushed, db_ticks_count
   - Dashboard: Real-time data flow visualization
   - Alerts: No data for 2min during market hours = CRITICAL

5. **CI/CD Pipeline Updates**
   - Add deployment verification step
   - Auto-rollback on smoke test failure
   - Deployment notifications (Slack)

6. **Data Quality Monitoring**
   - Daily report: ticks/hour during market hours
   - Alert if < 3,000 ticks/hour
   - Backfill SOP for gap recovery

### Long-Term (This Month)

7. **Deployment Runbook Library**
   - Standard procedures for all services
   - Troubleshooting decision trees
   - Escalation paths

8. **Incident Review Process**
   - Weekly incident review meeting
   - Root cause analysis required
   - Prevention tracking

9. **Documentation Culture**
   - No deployment without docs
   - Runbook-first development
   - Knowledge sharing sessions

---

## Lessons Learned

### What Went Wrong

1. **Assumed services were resilient** (they weren't)
2. **Deployed without verification** (hope-based deployment)
3. **Didn't document previous failures** (repeated mistakes)
4. **No monitoring = blind operations** (found problems by accident)
5. **Treated symptoms, not disease** (fixed collector, missed archiver)

### What Went Right

1. **Emergency response was fast** (once problem identified)
2. **Root cause analysis was thorough** (Council of Six)
3. **User feedback was immediate and actionable**
4. **Team acknowledged systemic issues** (no blame game)

### Key Takeaway

> **"Documentation is not 'nice to have'. It's how we stop being stupid."**  
> ‚Äî Doc Specialist, Council of Six

**Recurring failures are not bad luck. They're bad process.**

---

## Follow-Up Actions

### Assigned Tasks

| Task | Owner | Deadline | Status |
|------|-------|----------|--------|
| Incident Report | Developer | 17:00 Today | ‚úÖ DONE |
| Runbook | Doc Specialist | 17:00 Today | ‚è≥ IN PROGRESS | 
| Deployment Checklist | Doc Specialist | 17:00 Today | ‚è≥ TODO |
| Monitoring Requirements | Infra | 17:00 Today | ‚è≥ TODO |
| Smoke Tests | QA | End of Week | ‚è≥ TODO |
| Prometheus Setup | Infra | Next Week | ‚è≥ TODO |

### Review Schedule

- **17:00 Today**: PM + Doc review documents ‚Üí Lift freeze if complete
- **09:00 Tomorrow**: Monitor morning market open (validation test)
- **Friday 17:00**: Week review - assess if 48hr monitoring passed

---

## Appendix

### Related Commits

- **8781ff5**: fix(collector): add explicit unsubscribe before WebSocket reconnect
- **4fe80ca**: fix(archiver): add restart policy to timescale-archiver

### Related Documents

- Implementation Plan: `brain/implementation_plan.md` (Council deliberation)
- Task List: `brain/task.md` (current priorities)
- Monitoring Log: `brain/monitoring_log.md` (real-time checks)

### Contact

For questions about this incident:
- Technical: Antigravity Dev Team
- Process: PM (Council of Six)
- Escalation: [TBD]

---

**Report Completed**: 2026-01-15 14:45 KST  
**Next Review**: 2026-01-16 09:00 KST (Market Open)
