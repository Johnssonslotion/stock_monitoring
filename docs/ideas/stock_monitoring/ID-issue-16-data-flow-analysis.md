# 아이디어: Issue 16 데이터 흐름 및 테스트 전략 분석

**대상**: ISSUE-015 (데이터 누락 자동 보완)
**배경**: BACKLOG 불일치(Issue 15 vs 16) 확인 및 견고한 테스트 전략 수립 필요
**상태**: 🌿 발아 (분석 단계)

---

## 1. 매크로 데이터 흐름: 주식 데이터 수집 범위
*전체 데이터 수집 과정의 데이터 흐름도 및 테스트 전략 점검*

### 데이터 흐름 단계 (Data Flow Stages)
1.  **트리거 (스케줄러/신호)**
    *   *입력*: 시장 시작 시간 또는 이벤트
    *   *처리*: `Orchestrator`가 활성 수집 대상을 결정
    *   *출력*: 수집 작업 목록
2.  **연결 (브로커 인터페이스)**
    *   *입력*: 인증 토큰, 웹소켓 URL
    *   *처리*: KIS/키움 증권 서버 접속 및 구독
    *   *출력*: 연결된 데이터 스트림
3.  **수집 (Ingestion - 원천 포착)**
    *   *입력*: 바이너리/JSON 패킷
    *   *처리*: `RawQueue` 버퍼링 (지연 격리)
    *   *출력*: 버퍼링된 원천 데이터
4.  **처리 (Normalization - 정규화)**
    *   *입력*: 원천 데이터
    *   *처리*: 파싱 -> 유효성 검증 -> 표준 스키마(`TickData`) 변환
    *   *출력*: 구조화된 객체
5.  **저장 (Persistence)**
    *   *입력*: 구조화된 객체
    *   *처리*: `TimescaleDB` / `DuckDB`로 배치 삽입
    *   *출력*: 영구 저장된 레코드
6.  **전파 (Real-time Distribution)**
    *   *입력*: 구조화된 객체
    *   *처리*: Redis Pub/Sub (`market:ticks`) 발행
    *   *출력*: 대시보드/분석기로 스트리밍

### 테스트 전략 점검 (매크로)
| 단계 | 검토 포인트 | 현재 상태 | 필요 조치 |
| :--- | :--- | :--- | :--- |
| **수집** | 네트워크 장애, 버퍼 오버플로우 | ⚠️ 부분적 (재시도 로직 있음) | **카오스 테스트(Chaos Test)**: 강제 연결 해제 시나리오 필요 |
| **처리** | 파서 정확성, 스키마 검증 | ✅ 양호 (단위 테스트 있음) | **퍼징(Fuzzing)**: 비정상 패킷 주입 테스트 필요 |
| **저장** | 쓰기 처리량, 중복 방지 | ⚠️ 취약 (DB 의존적) | **부하 테스트** 및 **무결성 검증**(Issue 16) 로직 필요 |

---

## 2. 마이크로 데이터 흐름: Issue 16 (데이터 누락 복구)
*데이터 누락 보완(Recovery) 프로세스의 상세 흐름 및 테스트 케이스 점검*

### 프로세스 흐름
1.  **감지 (Integrity Checker)**
    *   *입력*: `DuckDB` (저장된 틱), `MarketHours` (장 운영시간)
    *   *처리*: 타임스탬프 연속성 스캔 (1초 이상 공백?)
    *   *출력*: `GapReport` (종목, 시작시간, 종료시간)
2.  **복구 실행 (Recovery Worker)**
    *   *입력*: `GapReport`
    *   *처리*: 키움 `opt10079` (주식틱차트조회) TR 요청 (누락 구간 대상)
    *   *출력*: 복구된 원천 데이터 리스트
3.  **병합 (Deduplication - 중복 제거)**
    *   *입력*: 복구된 데이터 + 기존 데이터
    *   *처리*: 파싱 -> 기존 타임스탬프 필터링 -> 신규 데이터만 삽입
    *   *출력*: 정제된 `DuckDB` 테이블
4.  **검증 (Post-Check)**
    *   *입력*: 업데이트된 `DuckDB`
    *   *처리*: 무결성 검사기 재실행
    *   *출력*: 성공/실패 상태

### 테스트 케이스 검증 (Issue 16)
현재 명세에는 엣지 케이스(Edge Case) 고려가 부족함. 다음 항목 추가 필요:

*   **TC1 [감지]**: 장중 발동된 서킷브레이커/VI를 누락(Gap)으로 오인하지 않는가?
*   **TC2 [감지]**: 실제 거래가 없는(거래량 0) 구간을 누락으로 오인하지 않는가?
*   **TC3 [복구]**: 키움 API가 해당 구간 데이터 제공 실패(타임아웃/빈값) 시 재시도 전략은?
*   **TC4 [병합]**: 기존 데이터와 1ms 차이로 겹치는 중복 데이터 처리 로직은? (시간 윈도우 중첩)
*   **TC5 [한계]**: 1시간 이상의 대량 누락 발생 시, API 제한을 고려한 분할 요청(Pagination)이 가능한가?

---

## 3. 6인 페르소나 분석 (위원회 검토)
*각 역할별 관점에서 본 Issue 16 분석 및 피드백*

### 🐯 아키텍트 (Architecture & Scalability)
> "복구 로직은 언제나 **멱등성(Idempotency)**이 보장되어야 합니다. 같은 구간을 10번 복구 시도해도 결과는 항상 하나여야 합니다. DuckDB는 PK 제약이 느슨하므로, 삽입 시 **Anti-Join 쿼리**를 사용하여 원천적으로 중복을 차단해야 합니다."

### 🐶 데이터 엔지니어 (Data Quality & Pipeline)
> "데이터가 '없는 것'과 '누락된 것'은 다릅니다. 거래량이 적은 소형주는 수십 분간 틱이 없을 수 있습니다. 단순히 시간 차이(`delta > 1s`)만으로 판단하면 오탐지(False Positive)가 폭증합니다. **체결 번호(Sequence)**의 연속성을 확인하거나, 거래량 0인 구간은 예외 처리하는 정교한 로직이 필수입니다."

### 🐻 개발자 (Implementation & Feasibility)
> "키움 `opt10079` TR은 한 번에 900개 틱만 제공합니다. 1시간 분량 누락 시 수십 번의 **페이지네이션(Pagination)** 요청이 필요하며, 이는 구현 복잡도가 높습니다. P0 긴급 이슈인 만큼, 일단 '최근 5분' 복구 기능을 먼저 구현하고 대량 복구는 후순위로 미루는 것을 제안합니다."

### 🐷 QA (Testing & Stability)
> "테스트 시나리오가 너무 정상 상황(Happy Path) 위주입니다. **새벽 점검 시간**에 복구 워커가 돌면 어떻게 됩니까? 무한 에러로 로그 파일을 채울 수 있습니다. **서킷 브레이커** 패턴(3회 연속 실패 시 중단)을 반드시 포함해야 합니다."

### 🐼 보안 담당 (Governance & Compliance)
> "복구를 위해 인위적으로 고빈도 트래픽을 발생시키는 행위가 증권사 약관에 위배되지 않는지 확인하십시오. 또한, 로그에는 이것이 '실시간 수집'인지 '사후 복구'인지 구분할 수 있는 **출처 태그(Source Flag)**를 남겨야 추후 데이터 감사가 가능합니다."

### 🐰 프로덕트 오너 (Value & Priority)
> "과거의 완벽한 복구보다 **'오늘 장중 데이터'의 신뢰성**이 우선입니다. 실시간 복구 가능성을 열어두고 설계를 잡아주세요. 그리고 현재 백로그 상의 Issue 15와 16번의 내용 혼선(파일과 제목 불일치)부터 즉시 정리해주시기 바랍니다."

---

## 4. 실행 계획 (Action Items)
1.  **백로그 정리**: `BACKLOG.md` 상의 Issue 15(대시보드)와 16(데이터 누락) 불일치 수정.
2.  **명세 업데이트**: `ISSUE-015.md`에 다음 내용 반영:
    *   페이지네이션 로직 (개발자 피드백)
    *   오탐지 방지 전략 (데이터 엔지니어 피드백)
    *   멱등성 보장 방안 (아키텍트 피드백)
3.  **테스트 계획 수립**: 무거래 구간 및 네트워크 장애 상황에 대한 테스트 케이스 추가.
