"""
Test Suite: System Metrics Schema Validation (TS-TYPE-01)

ëª©ì : Sentinelì´ ë°œí–‰í•˜ëŠ” system metrics ë°ì´í„°ê°€ TimescaleArchiverì˜ ìŠ¤í‚¤ë§ˆì™€ íƒ€ì…ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦

ê´€ë ¨ ë¬¸ì„œ:
- FMEA: Section 3.4
- Test Registry: TS-TYPE-01
- Implementation Plan: TEST_IMPLEMENTATION_PLAN.md
"""

import asyncio
import json
import pytest
import asyncpg
from datetime import datetime
import os

# DB ì—°ê²° ì •ë³´
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", "5432"))
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASSWORD = os.getenv("DB_PASSWORD", "password")
DB_NAME = os.getenv("DB_NAME", "stockval")

# Redis ì—°ê²° ì •ë³´
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6380/0")


@pytest.mark.asyncio
async def test_system_metrics_db_schema():
    """
    system_metrics í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê²€ì¦
    - labels ì»¬ëŸ¼ì´ jsonb íƒ€ì…ì¸ì§€ í™•ì¸
    """
    conn = await asyncpg.connect(
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME,
        host=DB_HOST,
        port=DB_PORT
    )

    try:
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        table_exists = await conn.fetchval(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'system_metrics')"
        )
        assert table_exists, "system_metrics table does not exist"

        # ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        schema = await conn.fetch("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name = 'system_metrics'
            ORDER BY ordinal_position
        """)

        schema_dict = {row['column_name']: row['data_type'] for row in schema}

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        assert 'time' in schema_dict, "Missing column: time"
        assert 'metric_name' in schema_dict, "Missing column: metric_name"
        assert 'value' in schema_dict, "Missing column: value"
        assert 'labels' in schema_dict, "Missing column: labels"

        # íƒ€ì… ê²€ì¦
        assert schema_dict['time'] == 'timestamp with time zone', \
            f"time column should be 'timestamp with time zone', got {schema_dict['time']}"
        assert schema_dict['metric_name'] == 'text', \
            f"metric_name column should be 'text', got {schema_dict['metric_name']}"
        assert schema_dict['value'] == 'double precision', \
            f"value column should be 'double precision', got {schema_dict['value']}"
        assert schema_dict['labels'] == 'jsonb', \
            f"labels column should be 'jsonb', got {schema_dict['labels']}"

        print(f"\nâœ… System Metrics Schema Validated:")
        for col, dtype in schema_dict.items():
            print(f"   - {col}: {dtype}")

    finally:
        await conn.close()


@pytest.mark.asyncio
async def test_system_metrics_type_validation():
    """
    Sentinelì´ ë°œí–‰í•˜ëŠ” system.metrics ë°ì´í„° êµ¬ì¡°ê°€
    TimescaleDB system_metrics í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì™€ íƒ€ì…ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦
    """
    conn = await asyncpg.connect(
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME,
        host=DB_HOST,
        port=DB_PORT
    )

    try:
        # í…ŒìŠ¤íŠ¸ìš© ë©”ì‹œì§€ (Sentinelì´ ë°œí–‰í•˜ëŠ” ì‹¤ì œ í˜•ì‹)
        test_messages = [
            # Legacy format (host metrics)
            {
                "timestamp": datetime.now().isoformat(),
                "cpu": 30.5,
                "mem": 45.2,
                "disk": 60.0
            },
            # New generic format (container status)
            {
                "timestamp": datetime.now().isoformat(),
                "type": "container_status",
                "value": 1.0,
                "meta": {"container": "test-container", "status": "running"}
            },
            # Redis metrics
            {
                "timestamp": datetime.now().isoformat(),
                "type": "redis_used_memory",
                "value": 1048576.0,
                "meta": {"status": "ok"}
            },
            # Governance metrics
            {
                "timestamp": datetime.now().isoformat(),
                "type": "governance_status",
                "value": 95.0,
                "meta": {
                    "status": "Healthy",
                    "p0_issues": 0,
                    "active_workflows": 10
                }
            }
        ]

        # TimescaleArchiver ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
        for idx, msg in enumerate(test_messages):
            ts = datetime.fromisoformat(msg['timestamp'])

            if 'cpu' in msg and 'mem' in msg:
                # Legacy format - ì—¬ëŸ¬ í–‰ìœ¼ë¡œ ë¶„í• 
                rows = [
                    (ts, 'cpu', float(msg['cpu']), None),
                    (ts, 'memory', float(msg['mem']), None)
                ]
                if 'disk' in msg:
                    rows.append((ts, 'disk', float(msg['disk']), None))

                # íƒ€ì… ê²€ì¦
                for row in rows:
                    assert len(row) == 4, "Row must have 4 columns"
                    assert isinstance(row[0], datetime), "time must be datetime"
                    assert isinstance(row[1], str), "metric_name must be str"
                    assert isinstance(row[2], float), "value must be float"
                    assert isinstance(row[3], (type(None), str)), \
                        f"labels must be None or str (json string), got {type(row[3])}"

                # DB INSERT í…ŒìŠ¤íŠ¸
                await conn.executemany(
                    "INSERT INTO system_metrics (time, metric_name, value, labels) VALUES ($1, $2, $3, $4)",
                    rows
                )
                print(f"âœ… Message {idx+1} (Legacy format): Inserted {len(rows)} rows")

            else:
                # New generic format
                m_type = msg.get('type')
                val = float(msg.get('value'))

                # CRITICAL: metaë¥¼ json.dumpsë¡œ ë³€í™˜í•´ì•¼ í•¨
                labels = json.dumps(msg.get('meta')) if msg.get('meta') else None

                # íƒ€ì… ê²€ì¦
                assert isinstance(m_type, str), f"type must be str, got {type(m_type)}"
                assert isinstance(val, float), f"value must be float, got {type(val)}"
                assert isinstance(labels, (type(None), str)), \
                    f"labels must be None or str (json.dumps result), got {type(labels)}"

                # json.dumps ê²°ê³¼ê°€ valid JSONì¸ì§€ í™•ì¸
                if labels:
                    try:
                        json.loads(labels)
                    except json.JSONDecodeError as e:
                        pytest.fail(f"labels is not valid JSON: {e}")

                # DB INSERT í…ŒìŠ¤íŠ¸
                try:
                    await conn.execute(
                        "INSERT INTO system_metrics (time, metric_name, value, labels) VALUES ($1, $2, $3, $4)",
                        ts, m_type, val, labels
                    )
                    print(f"âœ… Message {idx+1} ({m_type}): Inserted successfully")
                except Exception as e:
                    pytest.fail(f"Failed to insert metric '{m_type}': {e}")

        # ì‚½ì…ëœ ë°ì´í„° ê²€ì¦
        count = await conn.fetchval(
            "SELECT COUNT(*) FROM system_metrics WHERE time > NOW() - INTERVAL '1 minute'"
        )
        assert count >= len(test_messages), \
            f"Expected at least {len(test_messages)} rows, got {count}"

        print(f"\nâœ… All {count} metrics inserted successfully")

        # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ë° íƒ€ì… í™•ì¸
        sample = await conn.fetch(
            "SELECT metric_name, value, labels FROM system_metrics WHERE time > NOW() - INTERVAL '1 minute' LIMIT 5"
        )

        print("\nğŸ“Š Sample Inserted Data:")
        for row in sample:
            print(f"   - {row['metric_name']}: {row['value']} | labels: {row['labels']}")

            # labelsê°€ jsonb íƒ€ì…ì¸ì§€ í™•ì¸ (dictë¡œ ë°˜í™˜ë¨)
            if row['labels'] is not None:
                assert isinstance(row['labels'], (dict, str)), \
                    f"labels should be dict or str, got {type(row['labels'])}"

    finally:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
        await conn.execute(
            "DELETE FROM system_metrics WHERE time > NOW() - INTERVAL '1 minute'"
        )
        await conn.close()


@pytest.mark.asyncio
async def test_sentinel_publisher_validation():
    """
    Sentinelì´ ì‹¤ì œë¡œ ë°œí–‰í•˜ëŠ” ë©”ì‹œì§€ë¥¼ subscribeí•˜ì—¬ íƒ€ì… ê²€ì¦
    (ì‹¤ì œ ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì¼ ë•Œë§Œ í…ŒìŠ¤íŠ¸)
    """
    try:
        from redis.asyncio import Redis
    except ImportError:
        pytest.skip("redis package not installed")

    try:
        redis = await Redis.from_url(REDIS_URL, decode_responses=True)
        await redis.ping()
    except Exception as e:
        pytest.skip(f"Redis not available: {e}")

    pubsub = redis.pubsub()
    await pubsub.subscribe("system.metrics")

    received = []

    async def collect_messages():
        async for message in pubsub.listen():
            if message['type'] == 'message':
                try:
                    data = json.loads(message['data'])
                    received.append(data)

                    # Validation
                    assert 'timestamp' in data, "timestamp field is required"

                    # timestampê°€ ISO formatì¸ì§€ í™•ì¸
                    try:
                        datetime.fromisoformat(data['timestamp'])
                    except ValueError:
                        pytest.fail(f"Invalid timestamp format: {data['timestamp']}")

                    # meta í•„ë“œê°€ ìˆìœ¼ë©´ dict íƒ€ì…ì´ì–´ì•¼ í•¨ (ë°œí–‰ ì‹œì )
                    if 'meta' in data:
                        assert isinstance(data['meta'], dict), \
                            f"meta must be dict at publish time, got {type(data['meta'])}"
                        print(f"âœ… Received metric: {data.get('type', 'legacy')} | meta: {data['meta']}")

                    if len(received) >= 3:  # 3ê°œ ë©”ì‹œì§€ ìˆ˜ì‹  í›„ ì¢…ë£Œ
                        break
                except json.JSONDecodeError as e:
                    pytest.fail(f"Invalid JSON in message: {e}")

    try:
        await asyncio.wait_for(collect_messages(), timeout=30)
    except asyncio.TimeoutError:
        pytest.skip("No system metrics published within 30 seconds (system may not be running)")
    finally:
        await redis.close()

    assert len(received) > 0, "Should receive at least one metric"
    print(f"\nâœ… Successfully validated {len(received)} real-time metrics")


@pytest.mark.asyncio
async def test_archiver_error_handling():
    """
    íƒ€ì… ë¶ˆì¼ì¹˜ ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ Archiverê°€ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ”ì§€ ê²€ì¦
    """
    conn = await asyncpg.connect(
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME,
        host=DB_HOST,
        port=DB_PORT
    )

    try:
        # ì˜ëª»ëœ íƒ€ì… (dictë¥¼ ì§ì ‘ ì „ë‹¬)
        invalid_message = {
            "timestamp": datetime.now(),
            "type": "test_metric",
            "value": 100.0,
            "meta": {"key": "value"}  # dictë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬ (ì˜ëª»ë¨)
        }

        ts = invalid_message['timestamp']
        m_type = invalid_message['type']
        val = invalid_message['value']
        labels = invalid_message['meta']  # dictë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬

        # ì—ëŸ¬ ë°œìƒ ì˜ˆìƒ
        with pytest.raises(Exception) as exc_info:
            await conn.execute(
                "INSERT INTO system_metrics (time, metric_name, value, labels) VALUES ($1, $2, $3, $4)",
                ts, m_type, val, labels
            )

        print(f"\nâœ… Correctly rejected invalid type: {exc_info.value}")
        assert "expected str, got dict" in str(exc_info.value) or \
               "invalid input" in str(exc_info.value).lower(), \
            "Should reject dict type for labels column"

    finally:
        await conn.close()


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    sys.exit(pytest.main([__file__, "-v"]))
